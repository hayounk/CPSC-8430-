{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wgan_test.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1jDiy4kSJgGy6Xc9sg-vmS2JKtFjSeekM",
      "authorship_tag": "ABX9TyMghsjjb3OzJSG5RJGkr9k3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AejvSSW8Y1EI"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import clip_grad_value_\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import RMSprop\n",
        "import os\n",
        "from IPython.display import Image\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCZLIhbAY46D"
      },
      "source": [
        "cifar10 = CIFAR10(root='data', \n",
        "              train=True, \n",
        "              download=True,\n",
        "              transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "\n",
        "img, label = cifar10[0]\n",
        "print('Label: ', label)\n",
        "print(img[:,10:15,10:15])\n",
        "torch.min(img), torch.max(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QxTX87iZN5n"
      },
      "source": [
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd7F0FEJZXkL"
      },
      "source": [
        "img_norm = denorm(img)\n",
        "plt.imshow(img_norm[0])\n",
        "print('Label:', label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YBq4AlUZaSp"
      },
      "source": [
        "batch_size = 64\n",
        "latent_size = 100\n",
        "data_loader = DataLoader(cifar10, batch_size, shuffle=True, num_workers = 2, pin_memory = True)\n",
        "\n",
        "for img_batch, label_batch in data_loader:\n",
        "    print('first batch')\n",
        "    print(img_batch.shape)\n",
        "    plt.imshow(img_batch[0][0], cmap='gray')\n",
        "    print(label_batch)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4iT35NrZnUq"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBtia1hkZxir"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9iWBSrbcAu7"
      },
      "source": [
        "def wasserstein_loss(labels, output):\n",
        "    return torch.mean(labels * output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJUbNUvfcDlz"
      },
      "source": [
        "critic = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 1, 4, 1, 0),\n",
        "            nn.Linear(1,1)\n",
        "        )\n",
        "\n",
        "# Create the critic\n",
        "critic.to(device)\n",
        "  \n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "critic.apply(weights_init)\n",
        "\n",
        "# Print the critic\n",
        "print(critic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g_Jp6_Gxe9S"
      },
      "source": [
        "netD = critic\n",
        "netD.to(device)\n",
        "\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejk87bwhcEHQ"
      },
      "source": [
        "G = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_size, 256, 4, 1, 0),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "G.to(device)\n",
        "G.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJhPgqs1wnDq"
      },
      "source": [
        "netG = G\n",
        "\n",
        "netG.to(device)\n",
        "netG.apply(weights_init)\n",
        "\n",
        "print(netG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKTY_3EEcGLO"
      },
      "source": [
        "critic_optimizer = RMSprop(critic.parameters(), lr=5e-5)\n",
        "g_optimizer = RMSprop(G.parameters(), lr=5e-5)\n",
        "criterion = wasserstein_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyfk5mfH8Kpm"
      },
      "source": [
        "real_label = 0.9\n",
        "fake_label = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a4qp8bscI0z"
      },
      "source": [
        "def reset_grad():\n",
        "    critic_optimizer.zero_grad()\n",
        "    g_optimizer.zero_grad()\n",
        "\n",
        "def train_critic(images, grad_clip = 0.01):\n",
        "    # Create the labels which are later used as input for the BCE loss\n",
        "    real_labels = -torch.ones(batch_size, 1, 1, 1).to(device)\n",
        "    fake_labels = torch.ones(batch_size, 1, 1, 1).to(device)\n",
        "        \n",
        "    # Loss for real images\n",
        "    outputs = critic(images)\n",
        "    critic_loss_real = criterion(outputs, real_labels)\n",
        "    real_score = outputs\n",
        "\n",
        "    # Loss for fake images\n",
        "    z = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
        "    fake_images = G(z)\n",
        "    outputs = critic(fake_images)\n",
        "    critic_loss_fake = criterion(outputs, fake_labels)\n",
        "    fake_score = outputs\n",
        "\n",
        "    # Combine losses\n",
        "    critic_loss = critic_loss_real + critic_loss_fake\n",
        "    # Reset gradients\n",
        "    reset_grad()\n",
        "    # Compute gradients\n",
        "    critic_loss.backward()\n",
        "    clip_grad_value_(critic.parameters(), grad_clip)\n",
        "    # Adjust the parameters using backprop\n",
        "    critic_optimizer.step()\n",
        "    \n",
        "    return critic_loss, real_score, fake_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4136QrdcK8H"
      },
      "source": [
        "def train_generator(grad_clip = 0.01):\n",
        "    # Generate fake images and calculate loss\n",
        "    z = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
        "    fake_images = G(z)\n",
        "    labels = -torch.ones(batch_size, 1, 1, 1).to(device)\n",
        "    g_loss = criterion(critic(fake_images), labels)\n",
        "\n",
        "    # Backprop and optimize\n",
        "    reset_grad()\n",
        "    g_loss.backward()\n",
        "    clip_grad_value_(G.parameters(), grad_clip)\n",
        "    g_optimizer.step()\n",
        "    return g_loss, fake_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TLIZC8pjHf9"
      },
      "source": [
        "sample_dir = 'samples'\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WC78XA5jLA3"
      },
      "source": [
        "for images, _ in data_loader:\n",
        "    images = images.reshape(images.size(0), 3, 32, 32)\n",
        "    save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'), nrow=8)\n",
        "    break\n",
        "   \n",
        "Image(os.path.join(sample_dir, 'real_images.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEa99oEXjOnl"
      },
      "source": [
        "sample_vectors = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
        "\n",
        "def save_fake_images(index):\n",
        "    fake_images = G(sample_vectors)\n",
        "    fake_images = fake_images.reshape(fake_images.size(0), 3, 32, 32)\n",
        "    fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n",
        "    print('Saving', fake_fname)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuM7Pc0OZD9A"
      },
      "source": [
        "sample_dir = 'samples2'\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAj7EggHZFu2"
      },
      "source": [
        "num_epochs = 100\n",
        "d_losses, g_losses, real_scores, fake_scores = [], [], [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader) :\n",
        "        # Load a batch & transform to vectors\n",
        "        images = images.to(device)\n",
        "        #print(i)\n",
        "        \n",
        "        #print('hello')\n",
        "        if images.shape != torch.Size([64, 3, 32, 32]):\n",
        "             continue\n",
        "        # Train the discriminator and generator\n",
        "        \n",
        "        for i in range(5) :    \n",
        "            d_loss, real_score, fake_score = train_critic(images)\n",
        "        else : \n",
        "            continue\n",
        "\n",
        "        g_loss, fake_images = train_generator()\n",
        "\n",
        "        if ((i+1) % 100 == 0) :\n",
        "            d_losses.append(d_loss.item())\n",
        "            g_losses.append(g_loss.item())\n",
        "            real_scores.append(real_score.mean().item())\n",
        "            fake_scores.append(fake_score.mean().item())\n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "                  .format(epoch, num_epochs, i+1, len(data_loader), d_loss.item(), g_loss.item(), \n",
        "                          real_score.mean().item(), fake_score.mean().item()))\n",
        "        \n",
        "        # Inspect the losses\n",
        "        \n",
        "        \n",
        "    # Sample and save images\n",
        "    save_fake_images(epoch+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgOVt0wnc714"
      },
      "source": [
        "num_epochs = 50\n",
        "d_losses, g_losses, real_scores, fake_scores = [], [], [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        # Load a batch & transform to vectors\n",
        "        images = images.to(device)\n",
        "        if images.shape != torch.Size([64, 3, 32, 32]):\n",
        "            continue\n",
        "        # Train the discriminator and generator\n",
        "        \n",
        "        for i in range(5):    \n",
        "            d_loss, real_score, fake_score = train_critic(images)\n",
        "        g_loss, fake_images = train_generator()\n",
        "        \n",
        "        # Inspect the losses\n",
        "        if (i+1) % 200 == 0:\n",
        "            d_losses.append(d_loss.item())\n",
        "            g_losses.append(g_loss.item())\n",
        "            real_scores.append(real_score.mean().item())\n",
        "            fake_scores.append(fake_score.mean().item())\n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
        "                          real_score.mean().item(), fake_score.mean().item()))\n",
        "        #print('hello')\n",
        "        break\n",
        "        \n",
        "    # Sample and save images\n",
        "    save_fake_images(epoch+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-JKPS1PlRN5"
      },
      "source": [
        "Reference : https://www.kaggle.com/cookiefinder/wgan-cifar10"
      ]
    }
  ]
}